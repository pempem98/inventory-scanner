import os
import json
import time
import logging
import pandas as pd
from typing import Dict, List, Any, Optional
from collections import defaultdict

# Import c√°c module ƒë√£ ƒë∆∞·ª£c t√πy ch·ªânh
from DatabaseManager import DatabaseManager
from GoogleSheetDownloader import GoogleSheetDownloader
from TelegramNotifier import TelegramNotifier

# Thi·∫øt l·∫≠p logging
logging.basicConfig(
    filename='runtime.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    encoding='utf-8'
)

class WorkflowManager:
    """
    Qu·∫£n l√Ω lu·ªìng c√¥ng vi·ªác ch√≠nh: t·∫£i, so s√°nh, v√† th√¥ng b√°o d·ªØ li·ªáu
    d·ª±a tr√™n c·∫•u h√¨nh t·ª´ c∆° s·ªü d·ªØ li·ªáu SQLite.
    """

    def __init__(self, bot_token: str, proxies: Optional[Dict[str, str]] = None):
        """
        Kh·ªüi t·∫°o WorkflowManager.

        Args:
            bot_token: Token c·ªßa bot Telegram ƒë·ªÉ s·ª≠ d·ª•ng cho vi·ªác th√¥ng b√°o.
            proxies: C·∫•u h√¨nh proxy (n·∫øu c√≥).
        """
        self.db_manager = DatabaseManager()
        self.proxies = proxies
        # Kh·ªüi t·∫°o Notifier m·ªôt l·∫ßn ƒë·ªÉ t√°i s·ª≠ d·ª•ng
        if bot_token:
            self.notifier = TelegramNotifier(bot_token=bot_token, proxies=self.proxies)
        else:
            self.notifier = None
            logging.warning("Kh√¥ng c√≥ BOT_TOKEN, s·∫Ω kh√¥ng c√≥ th√¥ng b√°o n√†o ƒë∆∞·ª£c g·ª≠i.")

    def _find_header_and_columns(self, df: pd.DataFrame, config: dict) -> Optional[Dict[str, Any]]:
        """
        T·ª± ƒë·ªông t√¨m h√†ng header v√† v·ªã tr√≠ c√°c c·ªôt quan tr·ªçng d·ª±a v√†o c·∫•u h√¨nh.
        """
        key_col_aliases = [key.lower() for key in json.loads(config.get('key_column_aliases', '[]'))]
        price_col_aliases = [key.lower() for key in json.loads(config.get('price_column_aliases', '[]'))]
        if not key_col_aliases:
            logging.error(f"D·ª± √°n {config['project_name']} kh√¥ng c√≥ 'key_column_aliases' ƒë∆∞·ª£c c·∫•u h√¨nh.")
            return None

        header_row_idx = -1

        # ∆Øu ti√™n 1: L·∫•y ch·ªâ s·ªë h√†ng ƒë∆∞·ª£c c·∫•u h√¨nh s·∫µn
        config_header_idx = config.get('header_row_index')
        if config_header_idx and 0 < config_header_idx <= len(df):
            header_row_idx = config_header_idx - 1
        else:
            # ∆Øu ti√™n 2: T·ª± ƒë·ªông qu√©t 10 d√≤ng ƒë·∫ßu ti√™n ƒë·ªÉ t√¨m header
            for i, row in df.head(10).iterrows():
                row_values = {str(val).strip().lower() for val in row.dropna().values}
                if not set(key_col_aliases).isdisjoint(row_values):
                    header_row_idx = i
                    break
        
        if header_row_idx == -1:
            logging.error(f"Kh√¥ng th·ªÉ t·ª± ƒë·ªông t√¨m th·∫•y h√†ng header cho d·ª± √°n {config['project_name']}.")
            return None
        
        header_content = [str(h).strip().lower() for h in df.iloc[header_row_idx].tolist()]

        # T√¨m v·ªã tr√≠ c·ªôt kh√≥a
        key_col_idx = None
        for alias in key_col_aliases:
            try:
                key_col_idx = header_content.index(alias)
                break
            except ValueError:
                continue
        
        if key_col_idx is None:
            logging.error(f"Kh√¥ng t√¨m th·∫•y c·ªôt kh√≥a n√†o cho d·ª± √°n {config['project_name']}.")
            return None

        # --- [M·ªöI] T√¨m c·ªôt gi√° (price) ---
        price_col_idx = None # C·ªôt gi√° c√≥ th·ªÉ kh√¥ng b·∫Øt bu·ªôc
        if price_col_aliases:
            for alias in price_col_aliases:
                try:
                    price_col_idx = header_content.index(alias)
                    break
                except ValueError:
                    continue
        
        if price_col_idx is None:
            logging.warning(f"Kh√¥ng t√¨m th·∫•y c·ªôt gi√° cho d·ª± √°n {config['project_name']}. B·ªè qua vi·ªác theo d√µi gi√°.")

        logging.info(f"ƒê√£ x√°c ƒë·ªãnh header ·ªü d√≤ng {header_row_idx + 1}. C·ªôt kh√≥a ·ªü v·ªã tr√≠ {key_col_idx}, C·ªôt gi√° ·ªü v·ªã tr√≠ {price_col_idx}.")

        # --- [M·ªöI] Tr·∫£ v·ªÅ c·∫£ price_col_idx ---
        return {
            "header_row_idx": header_row_idx,
            "key_col_idx": key_col_idx,
            "price_col_idx": price_col_idx,
            "header": header_content
        }

    def _normalize_and_validate_key(self, key: Any, prefixes: Optional[List[str]]) -> Optional[str]:
        """L√†m s·∫°ch v√† ki·ªÉm tra key c√≥ h·ª£p l·ªá v·ªõi c√°c ti·ªÅn t·ªë ƒë√£ cho kh√¥ng."""
        if not isinstance(key, (str, int, float)):
            return None
        
        clean_key = str(key).strip().upper()
        if not clean_key:
            return None
        
        if not prefixes:
            return clean_key # N·∫øu kh√¥ng c·∫•u h√¨nh prefix, m·ªçi key ƒë·ªÅu h·ª£p l·ªá

        for prefix in prefixes:
            if clean_key.startswith(prefix.upper()):
                return clean_key
        
        return None # Key kh√¥ng h·ª£p l·ªá

    def _extract_snapshot_data(self, data_df: pd.DataFrame, color_df: pd.DataFrame, header_info: dict, config: dict) -> Dict[str, Any]:
        """
        Tr√≠ch xu·∫•t d·ªØ li·ªáu snapshot t·ª´ DataFrame, c√≥ ki·ªÉm tra m√†u s·∫Øc kh√¥ng h·ª£p l·ªá.
        """
        snapshot_data = {}
        key_col_idx = header_info['key_col_idx']
        price_col_idx = header_info['price_col_idx']
        
        # L·∫•y c·∫•u h√¨nh m√†u kh√¥ng h·ª£p l·ªá t·ª´ DB
        invalid_colors_json = config.get('invalid_colors', '[]')
        invalid_colors = {c.lower() for c in json.loads(invalid_colors_json)}

        # L·∫•y DataFrame ch·ª©a d·ªØ li·ªáu v√† m√†u s·∫Øc th·ª±c t·∫ø (b·ªè c√°c d√≤ng tr√™n header)
        data_rows_df = data_df.iloc[header_info['header_row_idx'] + 1:]
        color_rows_df = color_df.iloc[header_info['header_row_idx'] + 1:]

        # L·∫•y c·∫•u h√¨nh ti·ªÅn t·ªë
        prefixes_json = config.get('key_prefixes')
        valid_prefixes = json.loads(prefixes_json) if prefixes_json else None

        for index, row in data_rows_df.iterrows():
            raw_key = row.iloc[key_col_idx]
            valid_key = self._normalize_and_validate_key(raw_key, valid_prefixes)

            if valid_key:
                # Ki·ªÉm tra m√†u s·∫Øc c·ªßa √¥ key
                try:
                    cell_color = color_rows_df.loc[index].iloc[key_col_idx]
                    if cell_color and cell_color.lower() in invalid_colors:
                        logging.info(f"B·ªè qua key '{valid_key}' do c√≥ m√†u kh√¥ng h·ª£p l·ªá: {cell_color}")
                        continue # B·ªè qua key n√†y v√† ƒëi ƒë·∫øn v√≤ng l·∫∑p ti·∫øp theo
                except (KeyError, IndexError):
                    # B·ªè qua n·∫øu kh√¥ng t√¨m th·∫•y m√†u t∆∞∆°ng ·ª©ng (√≠t khi x·∫£y ra)
                    pass

                price_value = None
                if price_col_idx is not None:
                    price_value = row.iloc[price_col_idx]

                # N·∫øu key h·ª£p l·ªá v√† m√†u h·ª£p l·ªá, th√™m v√†o snapshot\
                snapshot_data[valid_key] = {
                    "price": price_value
                }

        return snapshot_data

    def _compare_snapshots(self, new_snapshot: Dict, old_snapshot: Dict) -> Dict[str, List]:
        """So s√°nh hai snapshot, c√≥ th·ªÉ m·ªü r·ªông ƒë·ªÉ so s√°nh c·∫£ gi√°."""
        new_keys = set(new_snapshot.keys())
        old_keys = set(old_snapshot.keys())

        added = sorted(list(new_keys - old_keys))
        removed = sorted(list(old_keys - new_keys))
        
        changed = []
        # [M·ªöI] So s√°nh gi√° cho c√°c key chung
        common_keys = new_keys.intersection(old_keys)
        for key in common_keys:
            old_price = old_snapshot[key].get('price')
            new_price = new_snapshot[key].get('price')
            
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p gi√° l√† NaN ho·∫∑c None
            old_price_is_nan = pd.isna(old_price)
            new_price_is_nan = pd.isna(new_price)
            
            if old_price_is_nan and new_price_is_nan:
                continue # C·∫£ hai ƒë·ªÅu kh√¥ng c√≥ gi√° tr·ªã, coi nh∆∞ kh√¥ng ƒë·ªïi
            
            if old_price != new_price and not (old_price_is_nan and new_price_is_nan):
                 changed.append({
                    "key": key,
                    "field": "price",
                    "old": old_price,
                    "new": new_price
                 })

        return {'added': added, 'removed': removed, 'changed': changed}

    def run(self):
        """Ch·∫°y lu·ªìng c√¥ng vi·ªác ch√≠nh."""
        logging.info("="*50)
        logging.info("B·∫ÆT ƒê·∫¶U PHI√äN L√ÄM VI·ªÜC M·ªöI")
        
        active_configs = self.db_manager.get_active_configs()
        if not active_configs:
            logging.warning("Kh√¥ng c√≥ c·∫•u h√¨nh n√†o ƒëang ho·∫°t ƒë·ªông trong database. K·∫øt th√∫c.")
            return

        all_individual_results = []
        for config_row in active_configs:
            config = dict(config_row)
            agent_name = config['agent_name']
            project_name = config['project_name']
            config_id = config['id']
            
            print(f"\n‚ñ∂Ô∏è  ƒêang x·ª≠ l√Ω: {agent_name} - {project_name} (ID: {config_id})")

            try:
                # 1. T·∫£i d·ªØ li·ªáu t·ª´ Google Sheet
                downloader = GoogleSheetDownloader(
                    spreadsheet_id=config.get('spreadsheet_id'),
                    html_url=config.get('html_url'),
                    gid=config['gid'],
                    proxies=self.proxies
                )
                current_df, color_df, download_url = downloader.download()

                if current_df is None or color_df is None or current_df.empty:
                    logging.error(f"Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu ho·∫∑c m√†u s·∫Øc cho ID {config_id}.")
                    continue

                # 2. T√¨m header v√† c√°c c·ªôt quan tr·ªçng
                header_info = self._find_header_and_columns(current_df, config)
                if not header_info:
                    logging.error(f"Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c header/c·ªôt cho ID {config_id}.")
                    continue
                
                # 3. Tr√≠ch xu·∫•t d·ªØ li·ªáu snapshot hi·ªán t·∫°i
                new_snapshot = self._extract_snapshot_data(current_df, color_df, header_info, config)

                # 4. L·∫•y snapshot c≈© v√† so s√°nh
                old_snapshot = self.db_manager.get_latest_snapshot(config_id)
                
                if old_snapshot is not None:
                    comparison = self._compare_snapshots(new_snapshot, old_snapshot)
                    print(f"    -> So s√°nh ho√†n t·∫•t: {len(comparison['added'])} th√™m, {len(comparison['removed'])} b√°n, {len(comparison['changed'])} ƒë·ªïi.")
                else:
                    comparison = {'added': list(new_snapshot.keys()), 'removed': [], 'changed': []}
                    print("    -> L·∫ßn ƒë·∫ßu ch·∫°y, ghi nh·∫≠n to√†n b·ªô l√† cƒÉn m·ªõi.")

                if comparison.get('added') or comparison.get('removed') or comparison.get('changed'):
                    all_individual_results.append({
                        'agent_name': agent_name,
                        'project_name': project_name,
                        'telegram_chat_id': config['telegram_chat_id'],
                        'comparison': comparison
                    })

                self.db_manager.add_snapshot(config_id, new_snapshot)
                print(f"    -> ƒê√£ l∆∞u snapshot m·ªõi v·ªõi {len(new_snapshot)} keys.")

            except Exception as e:
                logging.exception(f"L·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω c·∫•u h√¨nh ID {config_id}: {e}")
                print(f"    ‚ùå L·ªói: {e}. Ki·ªÉm tra runtime.log ƒë·ªÉ bi·∫øt chi ti·∫øt.")

        print("\nüîÑ ƒêang t·ªïng h·ª£p v√† gom nh√≥m k·∫øt qu·∫£...")
        aggregated_results = defaultdict(lambda: {'added': [], 'removed': [], 'changed': [], 'telegram_chat_id': None})

        for result in all_individual_results:
            key = (result['agent_name'], result['project_name'])
            
            aggregated_results[key]['added'].extend(result['comparison']['added'])
            aggregated_results[key]['removed'].extend(result['comparison']['removed'])
            aggregated_results[key]['changed'].extend(result['comparison']['changed'])
            # L·∫•y chat_id, gi·∫£ ƒë·ªãnh c√°c c·∫•u h√¨nh con c·ªßa c√πng 1 d·ª± √°n c√≥ c√πng chat_id
            if not aggregated_results[key]['telegram_chat_id']:
                aggregated_results[key]['telegram_chat_id'] = result['telegram_chat_id']

        # B∆∞·ªõc 3: G·ª≠i th√¥ng b√°o t·ªïng h·ª£p
        print("üöÄ ƒêang g·ª≠i c√°c th√¥ng b√°o t·ªïng h·ª£p...")
        if not self.notifier:
            print("    -> B·ªè qua v√¨ kh√¥ng c√≥ BOT_TOKEN.")
            return

        for (agent_name, project_name), data in aggregated_results.items():
            chat_id = data['telegram_chat_id']
            if not chat_id:
                continue

            # T·∫°o m·ªôt dict k·∫øt qu·∫£ t·ªïng h·ª£p ƒë·ªÉ format
            final_result_for_message = {
                'agent_name': agent_name,
                'project_name': project_name,
                'comparison': {
                    'added': data['added'],
                    'removed': data['removed'],
                    'changed': data['changed']
                }
            }
            
            message = self.notifier.format_message(final_result_for_message)
            
            if message:
                print(f"    -> G·ª≠i th√¥ng b√°o cho: {agent_name} - {project_name}")
                self.notifier.send_message(chat_id, message)
                time.sleep(1) # T·∫°m d·ª´ng gi·ªØa c√°c tin nh·∫Øn
        
        self.db_manager.close()
        print("\n‚úÖ Ho√†n th√†nh t·∫•t c·∫£ c√°c t√°c v·ª•.")


if __name__ == "__main__":
    # L·∫•y BOT_TOKEN t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ƒë·ªÉ b·∫£o m·∫≠t
    # V√≠ d·ª•: export TELEGRAM_BOT_TOKEN="your_token_here"
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    proxies = {
        'http': 'http://rb-proxy-apac.bosch.com:8080',
        'https': 'http://rb-proxy-apac.bosch.com:8080'
    }
    if not bot_token:
        print("L·ªói: Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng TELEGRAM_BOT_TOKEN.")
    else:
        # Kh·ªüi t·∫°o v√† ch·∫°y workflow
        manager = WorkflowManager(bot_token=bot_token, proxies=None)
        manager.run()